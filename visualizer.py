import numpy as np
import cv2

def truncate_route(points, clip_dist=5.0):
    """
    å°‡è·¯å¾‘ points æˆªæ–·åˆ° clip_dist (å…¬å°º) é–‹å§‹ï¼Œä¸¦åœ¨ clip_dist è™•æ’å…¥äº¤é»ã€‚
    points: list of [x, y]ï¼Œy ç‚ºè»Šé ­å‰é€²æ–¹å‘è·é›¢
    clip_dist: æˆªæ–·é–€æª»ï¼Œä¿ç•™ y >= clip_dist çš„éƒ¨åˆ†
    è¿”å›æ–°çš„æˆªæ–·å¾Œè·¯å¾‘ list of [x, y]
    """
    truncated = []
    for i in range(len(points) - 1):
        x0, y0 = points[i]
        x1, y1 = points[i + 1]
        # è‹¥è·¨è¶Š clip_distï¼Œå…ˆåŠ ä¸Šä¸€å€‹äº¤é»
        if y0 < clip_dist and y1 >= clip_dist:
            t = (clip_dist - y0) / (y1 - y0)
            xc = x0 + (x1 - x0) * t
            yc = clip_dist
            truncated.append([xc, yc])
        # è‹¥åœ¨ clip_dist ä¹‹å¾Œï¼Œä¿ç•™é»
        if y1 >= clip_dist:
            truncated.append([x1, y1])
    return truncated

def draw_map_bev(viz_setting):
        # Assume there are multiple poses and only one route
        # Setting format:
        # {
        #     'poses': [
        #       {'pose': <x, y, heading of 1st pose>,
        #       'color': <[r, g, b] of 1st pose>,
        #       'radius': <Radius of 1st pose>},
        #       'heading_is_valid': 1 # Point with valid heading
        #       ...
        #       {'pose': <x, y, heading of Nth pose>,
        #       'color': <[r, g, b] of Nth pose>,
        #       'radius': <R of Nth pose>},
        #       'heading_is_valid': 0 # Pure point
        #     ]
        #     'route': {
        #         'points': [<x, y of 1st point>, ... <x, y of Mth point>],
        #         'color': <[r, g, b] of route>,
        #         'radius': <Radius of route points>
        #         'thickness': <Thickness of route>
        #     }
        #     'width': <image width>
        #     'height': <image height>
        # }
    width = int(viz_setting.get('width', 800))
    height = int(viz_setting.get('height', 600))
    pixel_per_meter = viz_setting.get('pixel_per_meter', 1.0)
    arrow_length_scale = 10

    image = np.ones((height, width, 3), dtype=np.uint8) * 255

    # ğŸš© Step 1. è¨­å®šä¸­å¿ƒé»ï¼ˆä¸–ç•Œåº§æ¨™ï¼‰
    center_pose = viz_setting.get('center_pose', [0, 0])  # é è¨­ä¸­å¿ƒåœ¨ (0,0)
    center_x, center_y = center_pose[0], center_pose[1]

    # ğŸš© Step 2. ç•«æ ¼ç·š
    grid_color = (200, 200, 200)
    font_color = (100, 100, 100)
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.4
    font_thickness = 1

    meter_step = 5  # æ¯5mä¸€æ¢ç·š
    pixel_step = int(pixel_per_meter * meter_step)

    origin_px = width // 2
    origin_py = height // 2

    # ç•«æ°´å¹³ç·š
    for y in range(0, height, pixel_step):
        cv2.line(image, (0, y), (width, y), grid_color, 1)
        world_y = (origin_py - y) / pixel_per_meter + center_y
        if abs(world_y) > 0.1:
            cv2.putText(image, f'{int(world_y)}', (origin_px + 3, y - 3), font, font_scale, font_color, font_thickness)

    # ç•«å‚ç›´ç·š
    for x in range(0, width, pixel_step):
        cv2.line(image, (x, 0), (x, height), grid_color, 1)
        world_x = (x - origin_px) / pixel_per_meter + center_x
        if abs(world_x) > 0.1:
            cv2.putText(image, f'{int(world_x)}', (x + 2, origin_py - 2), font, font_scale, font_color, font_thickness)

    # Step 3. ç•« route
    route_info = viz_setting.get('route', {})
    points = route_info.get('points', [])
    color = tuple(route_info.get('color', [255, 0, 0]))
    thickness = int(route_info.get('thickness', 2))
    radius = int(route_info.get('radius', 3))

    if len(points) >= 2:
        pts = []
        for x, y in points:
            rel_x = (x - center_x) * pixel_per_meter
            rel_y = (y - center_y) * pixel_per_meter
            px = int(origin_px + rel_x)
            py = int(origin_py - rel_y)
            pts.append((px, py))
            cv2.circle(image, (px, py), radius, color, -1)

        for i in range(1, len(pts)):
            cv2.line(image, pts[i-1], pts[i], color, thickness)

    # Step 4. ç•« sub_route
    route_info = viz_setting.get('sub_route', {})
    points = route_info.get('points', [])
    color = tuple(route_info.get('color', [255, 0, 0]))
    thickness = int(route_info.get('thickness', 2))
    radius = int(route_info.get('radius', 3))

    if len(points) >= 2:
        pts = []
        for x, y in points:
            rel_x = (x - center_x) * pixel_per_meter
            rel_y = (y - center_y) * pixel_per_meter
            px = int(origin_px + rel_x)
            py = int(origin_py - rel_y)
            pts.append((px, py))
            cv2.circle(image, (px, py), radius, color, -1)

        for i in range(1, len(pts)):
            cv2.line(image, pts[i-1], pts[i], color, thickness)

    # Step 5. ç•« poses
    for pose_info in viz_setting.get('poses', []):
        pose = pose_info['pose']  # (x, y, heading)
        color = tuple(pose_info.get('color', [0, 255, 255]))
        radius = int(pose_info.get('radius', 5))

        x, y, heading = pose
        rel_x = (x - center_x) * pixel_per_meter
        rel_y = (y - center_y) * pixel_per_meter

        px = int(origin_px + rel_x)
        py = int(origin_py - rel_y)

        cv2.circle(image, (px, py), radius, color, -1)

        if pose_info['heading_is_valid'] == 1:
            arrow_length = arrow_length_scale * pixel_per_meter
            dx = int(np.sin(heading) * arrow_length)
            dy = int(np.cos(heading) * arrow_length)
            cv2.arrowedLine(image, (px, py), (px + dx, py - dy), color, 2, tipLength=0.3)

    # 6. Draw legend in the top-right corner
    legend_font = cv2.FONT_HERSHEY_SIMPLEX
    legend_scale = 0.3
    legend_thickness = 1

    legend_x = width - 150   # left margin of legend area
    legend_y = 20            # starting y position
    line_height = 20

    for i, pose_info in enumerate(viz_setting.get('poses', [])):
        color = tuple(pose_info.get('color', [0, 255, 0]))
        name  = pose_info.get('name', f'Pose {i+1}')

        # Draw color box
        box_x1, box_y1 = legend_x, legend_y + i * line_height
        box_x2, box_y2 = box_x1 + 15, box_y1 + 15
        cv2.rectangle(image, (box_x1, box_y1), (box_x2, box_y2), color, -1)

        # Draw label text
        cv2.putText(image, name, (box_x2 + 5, box_y2 - 2),
                    legend_font, legend_scale, (0, 0, 0), legend_thickness)

    return image

def draw_vehicle_bev(viz_setting, vehicle_position=(0,0,0)):
    # 1. Read canvas size
    width = int(viz_setting.get('width', 800))
    height = int(viz_setting.get('height', 600))

    # 2. Define forward/backward visible distance (meters)
    backward_m = viz_setting.get('backward_meters', 10)   # 10 m behind the vehicle
    forward_m  = viz_setting.get('forward_meters',  70)   # 70 m ahead of the vehicle

    # 3. Compute pixel-per-meter scale based on canvas height
    pixel_per_meter = height / (forward_m + backward_m)
    arrow_length_scale = 10

    # 4. Compute vehicle origin in pixel coordinates
    origin_px = width  // 2
    origin_py = int(forward_m * pixel_per_meter)

    # 5. Create a white background image
    image = np.ones((height, width, 3), dtype=np.uint8) * 255

    # 6. Draw grid lines every 5 meters
    grid_color     = (200, 200, 200)
    font_color     = (100, 100, 100)
    font           = cv2.FONT_HERSHEY_SIMPLEX
    font_scale     = 0.4
    font_thickness = 1
    meter_step     = 5
    pixel_step     = int(pixel_per_meter * meter_step)

    # Horizontal grid lines with labels
    for y in range(0, height, pixel_step):
        cv2.line(image, (0, y), (width, y), grid_color, 1)
        world_y = (origin_py - y) / pixel_per_meter
        if abs(world_y) > 0.1:
            cv2.putText(image, f'{int(world_y)}m',
                        (origin_px + 3, y - 3),
                        font, font_scale, font_color, font_thickness)

    # Vertical grid lines with labels
    for x in range(0, width, pixel_step):
        cv2.line(image, (x, 0), (x, height), grid_color, 1)
        world_x = (x - origin_px) / pixel_per_meter
        if abs(world_x) > 0.1:
            cv2.putText(image, f'{int(world_x)}m',
                        (x + 2, origin_py - 2),
                        font, font_scale, font_color, font_thickness)

    # 7. Draw given poses if available
    for pose_info in viz_setting.get('poses', []):
        x, y, heading = pose_info['pose']
        color  = tuple(pose_info.get('color', [0, 255, 255]))
        radius = int(pose_info.get('radius', 5))

        rel_x = x * pixel_per_meter
        rel_y = y * pixel_per_meter
        px = int(origin_px + rel_x)
        py = int(origin_py - rel_y)

        cv2.circle(image, (px, py), radius, color, -1)
        if pose_info.get('heading_is_valid', 0) == 1:
            arrow_px = arrow_length_scale * pixel_per_meter
            dx = int(np.cos(heading) * arrow_px)
            dy = int(np.sin(heading) * arrow_px)
            cv2.arrowedLine(image, (px, py),
                            (px + dx, py - dy),
                            color, 2, tipLength=0.3)

    # 8. Draw truncated routes
    clip_dist = viz_setting.get('clip_distance', 5.0)
    routes = viz_setting.get('routes')

    for route_info in routes:
        original_points = route_info.get('points', [])
        truncated = truncate_route(original_points, clip_dist)
        if len(truncated) < 2:
            continue

        color     = tuple(route_info.get('color', [0, 255, 0]))
        thickness = int(route_info.get('thickness', 2))
        radius    = int(route_info.get('radius', 3))

        pix_pts = []
        for x, y in truncated:
            rel_x = x * pixel_per_meter
            rel_y = y * pixel_per_meter
            px = int(origin_px + rel_x)
            py = int(origin_py - rel_y)
            pix_pts.append((px, py))
            cv2.circle(image, (px, py), radius, color, -1)
        for i in range(1, len(pix_pts)):
            cv2.line(image, pix_pts[i-1], pix_pts[i], color, thickness)

    # 9. Draw legend in the top-right corner
    legend_font = cv2.FONT_HERSHEY_SIMPLEX
    legend_scale = 0.3
    legend_thickness = 1

    legend_x = width - 150   # left margin of legend area
    legend_y = 20            # starting y position
    line_height = 20

    for i, route_info in enumerate(routes):
        color = tuple(route_info.get('color', [0, 255, 0]))
        name  = route_info.get('name', f'Route {i+1}')

        # Draw color box
        box_x1, box_y1 = legend_x, legend_y + i * line_height
        box_x2, box_y2 = box_x1 + 15, box_y1 + 15
        cv2.rectangle(image, (box_x1, box_y1), (box_x2, box_y2), color, -1)

        # Draw label text
        cv2.putText(image, name, (box_x2 + 5, box_y2 - 2),
                    legend_font, legend_scale, (0, 0, 0), legend_thickness)

    return image

def draw_cam_view(image, veh_to_cam_rot, veh_to_cam_trans, calib_mat, viz_setting):
        # Assume there are multiple routes in vehicle BEV
        # Setting format: 
        # {
        #     'routes': [
        #       {'route': [<x, y of 1st point>, ... <x, y of last point of 1st route>], 
        #       'color': <[r, g, b] of 1st route>, 
        #       ...
        #       {'route': [<x, y of 1st point>, ... <x, y of last point of Nth route>], 
        #       'color': <[r, g, b] of Nth route>,
        #     ]
        #     'width': <width of vBEV carpet>,
        #     'radius': <Radius of image route point>,
        # }
        # Project vehicle BEV routes into image by camera parameters 
        # (veh_to_cam_rot, veh_to_cam_trans, calib_mat)
        
    # è¨ˆç®— camera_extrinsicï¼ˆå¦‚åŸæœ¬ï¼‰
    camera_extrinsic = np.eye(4)
    camera_extrinsic[:3, :3] = veh_to_cam_rot
    camera_extrinsic[:3, 3] = veh_to_cam_rot @ veh_to_cam_trans  # ä¿®æ­£ç‚ºçŸ©é™£ç›¸ä¹˜

    # å–å›ç•«å¯¬åº¦èˆ‡é»åŠå¾‘
    width  = viz_setting.get('width', 1)
    radius = viz_setting.get('radius', 5)
    max_distance = viz_setting.get('max_distance', 30)  # åŠ å…¥æœ€å¤§è·é›¢è¨­å®šï¼ˆé è¨­ 30 å…¬å°ºï¼‰
    alpha = viz_setting.get('alpha', 0.4)  # åŠ å…¥é€æ˜åº¦è¨­å®šï¼ˆé è¨­ 0.4ï¼‰

    # å…ˆåœ¨ cam_view ä¸Šç•«è»Šé“ç·š
    cam_img = image.copy()
    overlay = cam_img.copy()  # å»ºç«‹ overlay åœ–å±¤

    for route_info in viz_setting.get('routes', []):
        route = np.array(route_info['route'])   # N x 2 ä¸–ç•Œåº§æ¨™
        # â€”â€” åœ¨é€™è£¡åšæˆªæ–· â€”â€” 
        clip_dist = viz_setting.get('clip_distance', 5.0)
        truncated = truncate_route(route.tolist(), clip_dist)
        route = np.array(truncated)              # åªä¿ç•™å¾ 5m é–‹å§‹çš„é»ï¼Œä¸¦å«äº¤é»
        if route.shape[0] < 2:
            continue   # æˆªæ–·å®Œæ²’é•·åº¦å°±è·³é
        color = tuple(route_info.get('color', [0,255,0]))

        # 1. å»ºç«‹å·¦å³é‚Šç•Œçš„é½Šæ¬¡åº§æ¨™ï¼š
        device_path = np.hstack([
            route[:,0].reshape(-1,1), 
            np.zeros((len(route),1)), 
            route[:,1].reshape(-1,1), 
            np.ones((len(route),1))
        ])
        device_path_l = device_path.copy(); device_path_l[:,0] -= width/2
        device_path_r = device_path.copy(); device_path_r[:,0] += width/2

        # 2. è½‰åˆ°ç›¸æ©Ÿåº§æ¨™ç³»ï¼Œå†éæ¿¾ z>0ï¼š
        t_l = (camera_extrinsic @ device_path_l.T).T
        t_r = (camera_extrinsic @ device_path_r.T).T
        valid = (t_l[:,2]>0) & (t_r[:,2]>0)
        t_l, t_r = t_l[valid], t_r[valid]

        if len(t_l)==0 or len(t_r)==0:
            continue

        # 3. æŠ•å½±åˆ°å½±åƒå¹³é¢ï¼ˆé½Šæ¬¡åº§æ¨™ï¼‰
        p_l = calib_mat @ t_l[:,:3].T     # shape (3, N)
        p_r = calib_mat @ t_r[:,:3].T
        
        # 4. å®‰å…¨åœ°åš homogeneous normalizationï¼ˆå…ˆ clone åˆ†æ¯ï¼Œå†åšé in-place é™¤æ³•ï¼‰
        den_l = p_l[2:3, :].clone()      # shape (1, N)
        den_r = p_r[2:3, :].clone()
        p_l = p_l / den_l                 # shape (3, N)
        p_r = p_r / den_r
        
        # 5. è½‰æˆæ•´æ•¸ pixel åº§æ¨™
        import torch

        # å¦‚æœ p_l, p_r æ˜¯ torch.Tensorï¼Œå°±å…ˆ .detach().cpu().numpy()
        if isinstance(p_l, torch.Tensor):
            p_l_np = p_l.detach().cpu().numpy()
            p_r_np = p_r.detach().cpu().numpy()
        else:
            p_l_np = p_l
            p_r_np = p_r
        
        # å››æ¨äº”å…¥å¾Œè½‰ int
        x_l = p_l_np[0].round().astype(int)
        y_l = p_l_np[1].round().astype(int)
        x_r = p_r_np[0].round().astype(int)
        y_r = p_r_np[1].round().astype(int)
        
        # çµ„æˆ (x,y) tuple list
        img_pts_l = list(zip(x_l, y_l))
        img_pts_r = list(zip(x_r, y_r))
        
        # ç”¨ fillPoly ç•«ã€Œåœ°æ¯¯ã€ï¼šå·¦å³é‚Šç•Œä¹‹é–“å¡«æ»¿è‰²å¡Š
        m = min(len(img_pts_l), len(img_pts_r))
        for i in range(1, m):
            quad = np.array([
                img_pts_l[i-1], img_pts_r[i-1],
                img_pts_r[i],   img_pts_l[i]
            ], dtype=np.int32).reshape(-1,1,2)

            # åœ¨ overlay ä¸Šç•«åœ°æ¯¯
            cv2.fillPoly(overlay, [quad], color)

    # æ‰€æœ‰åœ°æ¯¯ç•«å®Œå¾Œï¼Œä¸€æ¬¡æ€§åšé€æ˜ç–Šåˆ
    cv2.addWeighted(overlay, alpha, cam_img, 1 - alpha, 0, cam_img)

    return cam_img


def draw_lane(image, lanes, color=(255, 0, 0), radius=3, thickness=2):
    """
    lanes: List of lanes, each lane is a list of (x, y) tuples (in pixel coordinates)
    image: The image to draw lanes on
    color: Color of the lane (default yellow)
    radius: Radius of each point
    thickness: Thickness of connecting lines
    """
    for lane in lanes:
        if len(lane) < 2:
            continue  # è‡³å°‘éœ€è¦å…©å€‹é»æ‰èƒ½ç•«ç·š
        # ç•«é»
        for (x, y) in lane:
            cv2.circle(image, (int(x), int(y)), radius, color, -1)
        # ç•«ç·š
        for i in range(1, len(lane)):
            pt1 = (int(lane[i - 1][0]), int(lane[i - 1][1]))
            pt2 = (int(lane[i][0]), int(lane[i][1]))
            cv2.line(image, pt1, pt2, color, thickness)
    return image

# Add labels with optional color
def add_label(image, text, color=(255, 0, 0)):
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.8
    thickness = 2
    position = (10, 30)
    labeled = image.copy()
    cv2.putText(labeled, text, position, font, font_scale, color, thickness, cv2.LINE_AA)
    return labeled


def combine_images(cam_view, veh_bev, map_bev):
    """
    æ”¹ç‰ˆéœ€æ±‚ï¼š
    1) ç‚º Map BEV èˆ‡ Vehicle BEV å½±åƒåŠ ä¸Šç°è‰²çš„é‚Šç•Œæ¡†ã€‚
    2) Map BEV èˆ‡ Vehicle BEV å‚ç›´å †ç–Šï¼Œè‹¥å¯¬åº¦ä¸åŒï¼Œä»¥ Veh BEV å¯¬åº¦ç‚ºæº–ç¸®æ”¾ Map BEVã€‚
    3) å°‡(2)çš„å †ç–Šçµæœç¸®æ”¾ï¼Œä½¿å…¶é«˜åº¦èˆ‡ Cam View çš„é«˜åº¦ä¸€è‡´ï¼Œæœ€å¾Œèˆ‡ Cam View æ°´å¹³ä¸¦æ’ã€‚
    """
    if cam_view is None or veh_bev is None or map_bev is None:
        raise ValueError("âŒ æœ‰åœ–ç‰‡è®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªæª”æ¡ˆå­˜åœ¨")

    def _add_border(img, color=(150,150,150), thickness=2):
        bordered = img.copy()
        h, w = bordered.shape[:2]
        cv2.rectangle(bordered, (0,0), (w-1, h-1), color, thickness)
        return bordered

    vb_h, vb_w = veh_bev.shape[:2]
    mb_h, mb_w = map_bev.shape[:2]

    # Map BEV å¯¬åº¦å°é½Š veh_bev
    if mb_w != vb_w:
        scale = vb_w / float(mb_w)
        new_h = max(1, int(round(mb_h * scale)))
        map_bev_resized = cv2.resize(map_bev, (vb_w, new_h))
    else:
        map_bev_resized = map_bev

    # åŠ ä¸Šé‚Šæ¡†èˆ‡æ¨™ç±¤
    map_bev_labeled = add_label(map_bev_resized, "map_bev")
    veh_bev_labeled = add_label(veh_bev, "veh_bev")
    map_bev_bordered = _add_border(map_bev_labeled)
    veh_bev_bordered = _add_border(veh_bev_labeled)

    # å‚ç›´å †ç–Š
    bev_column = np.vstack((map_bev_bordered, veh_bev_bordered))

    # èª¿æ•´é«˜åº¦èˆ‡ cam_view ç›¸åŒ
    cam_h, cam_w = cam_view.shape[:2]
    col_h, col_w = bev_column.shape[:2]
    if col_h != cam_h:
        scale = cam_h / float(col_h)
        new_w = max(1, int(round(col_w * scale)))
        bev_column_resized = cv2.resize(bev_column, (new_w, cam_h))
    else:
        bev_column_resized = bev_column

    cam_labeled = add_label(cam_view, "cam_view", color=(255, 255, 0))

    # æœ€çµ‚å·¦å³ä¸¦æ’
    final_image = np.hstack((cam_labeled, bev_column_resized))
    return final_image

def combine_cam_view_veh_bev(cam_view, veh_bev):
    height, width = cam_view.shape[:2]

    # Resize BEV images
    bev_resized = cv2.resize(veh_bev, (width // 2, height))

    # Add texts
    bev_labeled = add_label(bev_resized, "veh_bev")                     # é è¨­é»ƒè‰²
    cam_labeled = add_label(cam_view, "cam_view", color=(255, 255, 0))  # æ·ºè—é»ƒè‰²ï¼ˆé’è‰²åé»ƒï¼‰

    # Adjust the height to be the same as that of cam_view
    cam_h, cam_w = cam_view.shape[:2]
    col_h, col_w = bev_labeled.shape[:2]
    if col_h != cam_h:
        scale = cam_h / float(col_h)
        new_w = max(1, int(round(col_w * scale)))
        bev_labeled = cv2.resize(bev_labeled, (new_w, cam_h))


    # Combine images
    final_image = np.hstack((cam_labeled, bev_labeled))

    return final_image

